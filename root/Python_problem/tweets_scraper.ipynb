{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDAS IIIT-D Summer Internship Task 1\n",
    "\n",
    "## Python Problem\n",
    "\n",
    "### Problem Statement -\n",
    "\n",
    "You have to write a python script which can fetch all the tweets(as many as allowed by Twitter API) done by 'midas@IIITD' twitter handle and dump the responses into JSONlines file.\n",
    "\n",
    "The other part of your script should be able to parse these JSONline files to display the following for every tweet in a tabular format.\n",
    "- The text of the tweet.\n",
    "- Date and time of the tweet.\n",
    "- The number of favorites/likes.\n",
    "- The number of retweets.\n",
    "- Number of Images present in Tweet. If no image returns None.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "1. [Importing libraries](#importing_libraries)\n",
    "2. [API Credentials](#api_credentials)\n",
    "3. [Getting ready for scraping twitter](#getting_started)\n",
    "4. [Scrape tweets](#scrape_tweets)\n",
    "5. [Save JSONLines file](#save_jsonl)\n",
    "6. [Parse JSONLines file](#parse_jsonl)\n",
    "7. [Display Table](#display_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='importing_libraries'></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries\n",
    "- pandas for tabular data formatting \n",
    "- tweepy for accessing Twitter API\n",
    "- json for writing and parsing JSONL files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tweepy \n",
    "from tweepy import OAuthHandler\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='api_credentials'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Twitter API keys and credentials from environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = os.getenv('ACCESS_TOKEN')\n",
    "ACCESS_TOKEN_SECRET = os.getenv('ACCESS_TOKEN_SECRET')\n",
    "CONSUMER_KEY = os.getenv('CONSUMER_KEY')\n",
    "CONSUMER_SECRET = os.getenv('CONSUMER_SECRET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='getting_started'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started with scraping twitter data\n",
    "\n",
    "- Define a class which initialises tweepy client object using api keys\n",
    "- Member function get_tweets() takes a twitter username as input and scrapes all tweets of that user\n",
    "- Tweets are scraped in batches of 100 so that the Twitter API is not abused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fetchTweets():\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "            auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "            \n",
    "            self.api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "            \n",
    "            '''\n",
    "            initialising an api object from tweepy using our credentials\n",
    "            '''\n",
    "\n",
    "        except tweepy.TweepError as e:\n",
    "            print(f'Error: Twitter Authentication Failed - {str(e)}')\n",
    "            \n",
    "    def get_tweets(self, screen_name):\n",
    "        '''\n",
    "        This function receives a twitter username as input and \n",
    "        scrapes all tweets for that specific user.\n",
    "        all_tweets is a list containing all tweet objects\n",
    "        We save the ID of last scraped tweet for every iteration \n",
    "        and use that as a reference to downlaod\n",
    "        tweets which haven't yet been scraped.\n",
    "        '''\n",
    "        all_tweets = []\n",
    "        \n",
    "        new_tweets = self.api.user_timeline(screen_name=screen_name, count=100, tweet_mode='extended')\n",
    "        \n",
    "        all_tweets.extend(new_tweets)\n",
    "        \n",
    "        oldest = all_tweets[-1].id - 1\n",
    "        \n",
    "        while len(new_tweets) > 0:\n",
    "            print(f\"Getting tweets before {oldest}\")\n",
    "            \n",
    "            new_tweets = self.api.user_timeline(screen_name=screen_name, count=100, max_id=oldest, tweet_mode='extended')\n",
    "            \n",
    "            all_tweets.extend(new_tweets)\n",
    "            \n",
    "            oldest = all_tweets[-1].id - 1\n",
    "            \n",
    "            print(f\"{len(all_tweets)} tweets have been scraped\")\n",
    "        return all_tweets\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising our fetchTweets class object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = fetchTweets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scrape_tweets'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call member function on object to start scraping all tweets of @midasIIITD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tweets before 1087712199836033023\n",
      "200 tweets have been scraped\n",
      "Getting tweets before 1037401364471508991\n",
      "296 tweets have been scraped\n",
      "Getting tweets before 1021377705084739583\n",
      "296 tweets have been scraped\n"
     ]
    }
   ],
   "source": [
    "tweets = twitter.get_tweets('midasIIITD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtags': [{'text': 'PortfolioCreationinDesign', 'indices': [39, 65]}],\n",
       " 'symbols': [],\n",
       " 'user_mentions': [{'screen_name': 'hcdiiitd',\n",
       "   'name': 'Human-Centered Design (IIITDelhi)',\n",
       "   'id': 1090887196754640896,\n",
       "   'id_str': '1090887196754640896',\n",
       "   'indices': [3, 12]}],\n",
       " 'urls': []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check - ensuring we're getting right data for a random tweet\n",
    "tweets[8]._json['entities']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to save tweets in a JSONLines file\n",
    "\n",
    "- JSONLines also called newline-delimited JSON. JSON Lines is a convenient format for storing structured data that may be processed one record at a time.\n",
    "- Each Line is a Valid JSON Value\n",
    "- Line Separator is '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jsonl(tweets):\n",
    "    '''\n",
    "    This function takes as input a list of tweets.\n",
    "    Tweepy represents these tweets as a list of Status objects.\n",
    "    In every iteration we parse the status object and extract the json data.\n",
    "    The json data is inserted in the file 'tweets.jsonl' with a '\\n' separator \n",
    "    to make it JSONLines compatible.\n",
    "    '''\n",
    "    with open('tweets.jsonl', 'w') as f:\n",
    "        for tweet in tweets:\n",
    "            json.dump(tweet._json, f)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_jsonl(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweets have been saved in a file 'tweets.jsonl' inside the current directory.\n",
    "The file can be parsed like so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'tweets_scraper.ipynb', 'tweets.jsonl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data of 'tweets.jsonl' file can be parsed as below\n",
    "# with open('tweets.jsonl') as f:\n",
    "#     for line in f:\n",
    "#         print(line)\n",
    "\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, a new file is created which contains all scraped tweets in jsonl format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to parse jsonl file\n",
    "- This function parses the jsonl file line by line and saves the required data in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_jsonl(filename):\n",
    "    '''\n",
    "    This function receives a jsonl file as input.\n",
    "    It parses this jsonl file line by line and\n",
    "    saves only the relevant details of each \n",
    "    tweet in a dictionary called tweets_dict.\n",
    "    '''\n",
    "    tweets_dict = {}\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            tweet = json.loads(line)\n",
    "            images = tweet['entities'].get('media', [])\n",
    "            tweets_dict.setdefault('text', []).append(tweet['full_text'])\n",
    "            tweets_dict.setdefault('datetime', []).append(tweet['created_at'])\n",
    "            tweets_dict.setdefault('favorite_count', []).append(tweet['favorite_count'])\n",
    "            tweets_dict.setdefault('retweet_count', []).append(tweet['retweet_count'])\n",
    "            tweets_dict.setdefault('media', []).append(len(images))\n",
    "\n",
    "    return tweets_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to display table \n",
    "- This function takes a dictionary as input and creates a dataframe using it\n",
    "- It then cleans the data and returns the dataframe in a presentable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_table(tweets_dict):\n",
    "    '''\n",
    "    This function takes a dictionary as input.\n",
    "    Data cleaning involves ordering the columns\n",
    "    because dictionary is an unordered object in Python.\n",
    "    0 Images are mapped to None and new line operators \n",
    "    are replaced by spaces.\n",
    "    '''\n",
    "    df = pd.DataFrame.from_dict(tweets_dict)\n",
    "    ordered_columns = ['text', 'datetime', 'favorite_count', 'retweet_count', 'media']\n",
    "    df = df.reindex(columns=ordered_columns)\n",
    "    df = df.replace('\\n', ' ', regex=True)\n",
    "    df['media'] = df['media'].map({0: 'None'}).fillna(df['media'])\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_tweets = parse_jsonl('tweets.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = display_table(parsed_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>datetime</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@IEEEBigMM19 is also available on Facebook now...</td>\n",
       "      <td>2019-03-20 08:19:24+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @IEEEBigMM19: BigMM 2019 : IEEE BigMM 2019 ...</td>\n",
       "      <td>2019-03-20 02:40:07+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BigMM 2019 : IEEE BigMM 2019 – Call for Worksh...</td>\n",
       "      <td>2019-03-18 02:27:47+00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Congratulations @midasIIITD team, Rohan, Prady...</td>\n",
       "      <td>2019-03-17 14:22:04+00:00</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have emailed the task details to all shortl...</td>\n",
       "      <td>2019-03-16 14:06:56+00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IEEE BigMM 2019 - Call for Workshop Proposals....</td>\n",
       "      <td>2019-03-16 09:20:29+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Congratulations! Arijit, Ramit, @debanjanbhucs...</td>\n",
       "      <td>2019-03-16 09:14:58+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We will be releasing a very interesting task t...</td>\n",
       "      <td>2019-03-16 05:13:14+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @hcdiiitd: Last day to register for #Portfo...</td>\n",
       "      <td>2019-03-13 17:09:44+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@ACMMM19 @sigmm @TheOfficialACM @acmmmsys @ACM...</td>\n",
       "      <td>2019-03-13 04:11:24+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT @ACMMM19: The paper deadline is approaching...</td>\n",
       "      <td>2019-03-13 04:06:04+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RT @kaggle: Bookmark this amazing library of i...</td>\n",
       "      <td>2019-03-12 17:43:44+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Awesome members of our @midasIIITD team who ar...</td>\n",
       "      <td>2019-03-12 14:37:55+00:00</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@saanidhi @ACMMM19 Before Friday, 15th March.</td>\n",
       "      <td>2019-03-11 14:58:30+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>We are glad to inform that Adobe is launching ...</td>\n",
       "      <td>2019-03-11 12:02:42+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>We will email tasks to all shortlisted candida...</td>\n",
       "      <td>2019-03-11 11:54:38+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@ACMMM19 @ACM_MM2018 @acmmm17 @sigmm @ACM Less...</td>\n",
       "      <td>2019-03-11 06:22:12+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RT @kdnuggets: Face Recognition using One-Shot...</td>\n",
       "      <td>2019-03-11 06:17:20+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@AvinashSwamina2 @IIITDelhi No. They will be g...</td>\n",
       "      <td>2019-03-08 13:22:07+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>We are in the process of finalizing the shortl...</td>\n",
       "      <td>2019-03-08 13:15:34+00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>@ylecun @NilayShri @the_dhumketu @debanjanbhuc...</td>\n",
       "      <td>2019-03-06 13:44:11+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RT @kdnuggets: Python Data Science for Beginne...</td>\n",
       "      <td>2019-03-06 11:12:30+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RT @stanfordnlp: Useful feature of our Python ...</td>\n",
       "      <td>2019-03-03 19:36:04+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>@NilayShri @NilayShri, Certain thing! The next...</td>\n",
       "      <td>2019-03-03 17:09:48+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>At @midasIIITD, we not only work hard but also...</td>\n",
       "      <td>2019-03-03 15:37:28+00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Considering several requests to extend the dea...</td>\n",
       "      <td>2019-03-03 14:55:31+00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RT @jeremyphoward: 39 studies about human perc...</td>\n",
       "      <td>2019-03-03 14:26:40+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Correction:   @midasIIITD at @IIITDelhi</td>\n",
       "      <td>2019-03-02 17:43:05+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Thanks much to all aspirants who have applied ...</td>\n",
       "      <td>2019-03-02 09:59:03+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RT @kdnuggets: Keras Hyperparameter Tuning in ...</td>\n",
       "      <td>2019-02-28 14:21:21+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>RT @TensorFlow: TensorFlow 1.10.0 has been rel...</td>\n",
       "      <td>2018-08-09 05:59:57+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>@midasIIITD is looking for motivated IIITD MTe...</td>\n",
       "      <td>2018-08-08 11:30:56+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>@IIITDelhi @ponguru @RatnRajiv The results of ...</td>\n",
       "      <td>2018-08-08 05:53:48+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>RT @IIITDelhi: @midasIIITD has secured rank 1 ...</td>\n",
       "      <td>2018-08-08 05:45:58+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>RT @kdnuggets: Comparison of Top 6 Python NLP ...</td>\n",
       "      <td>2018-08-07 07:16:33+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Check more details of the 20th IEEE Internatio...</td>\n",
       "      <td>2018-08-07 02:05:12+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>MR2AMC@ISM 2018 will be organized by @RatnRaji...</td>\n",
       "      <td>2018-08-07 01:58:49+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Our workshop proposal named, \"MR2AMC: Multimod...</td>\n",
       "      <td>2018-08-07 01:50:33+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>@NUSComputing Congratulations Abdelhak and Pro...</td>\n",
       "      <td>2018-08-06 17:48:23+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>RT @goodfellow_ian: One of the most anticipate...</td>\n",
       "      <td>2018-08-06 17:46:59+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>@the_dhumketu Great to have you in @midasIIITD</td>\n",
       "      <td>2018-08-06 06:06:47+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Congratulation @soujanyaporia for being appoin...</td>\n",
       "      <td>2018-08-03 05:56:33+00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>@IIITDelhi @the_dhumketu Thanks team @midasIII...</td>\n",
       "      <td>2018-08-01 11:47:15+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>RT @IIITDelhi: Congratulations @midasIIITD int...</td>\n",
       "      <td>2018-08-01 11:20:07+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>RT @learning_pt: Profile of the 5 Indian under...</td>\n",
       "      <td>2018-08-01 05:06:47+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Have a look at the list of accepted papers in ...</td>\n",
       "      <td>2018-07-31 12:11:52+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>RT @goodfellow_ian: https://t.co/hYiWI7ntyk Te...</td>\n",
       "      <td>2018-07-31 02:06:26+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>RT @IIITDelhi: Congratulations Dr. @RatnRajiv ...</td>\n",
       "      <td>2018-07-30 07:30:51+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>RT @ylecun: Jitendra Malik, who directs FAIR-M...</td>\n",
       "      <td>2018-07-28 11:07:11+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>RT @kdnuggets: .@Bloomberg launches free cours...</td>\n",
       "      <td>2018-07-28 06:14:09+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>RT @TechAtBloomberg: Missed #PyLondinium18? Wa...</td>\n",
       "      <td>2018-07-28 06:13:48+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>RT @IIITDelhi: We are delighted to announce th...</td>\n",
       "      <td>2018-07-28 04:08:21+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Get ready for the annual technical fest of @II...</td>\n",
       "      <td>2018-07-27 06:46:44+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Congratulations Dr. @RatnRajiv and team @midas...</td>\n",
       "      <td>2018-07-27 04:07:31+00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Congratulations MIDAS @midasIIITD intern Prakh...</td>\n",
       "      <td>2018-07-25 05:14:35+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>MIDAS@IIITD foundation. https://t.co/LKuzyBHzjm</td>\n",
       "      <td>2018-07-24 10:33:23+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>It feels great to be the part of @IIITDelhi. h...</td>\n",
       "      <td>2018-07-24 10:12:34+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Thank you, @toonzratn for designing the logo o...</td>\n",
       "      <td>2018-07-24 09:46:26+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>We are on Facebook too. Like our page to get o...</td>\n",
       "      <td>2018-07-23 16:25:05+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>MIDAS is a group of researchers at IIIT-Delhi ...</td>\n",
       "      <td>2018-07-23 12:53:15+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    @IEEEBigMM19 is also available on Facebook now...   \n",
       "1    RT @IEEEBigMM19: BigMM 2019 : IEEE BigMM 2019 ...   \n",
       "2    BigMM 2019 : IEEE BigMM 2019 – Call for Worksh...   \n",
       "3    Congratulations @midasIIITD team, Rohan, Prady...   \n",
       "4    We have emailed the task details to all shortl...   \n",
       "5    IEEE BigMM 2019 - Call for Workshop Proposals....   \n",
       "6    Congratulations! Arijit, Ramit, @debanjanbhucs...   \n",
       "7    We will be releasing a very interesting task t...   \n",
       "8    RT @hcdiiitd: Last day to register for #Portfo...   \n",
       "9    @ACMMM19 @sigmm @TheOfficialACM @acmmmsys @ACM...   \n",
       "10   RT @ACMMM19: The paper deadline is approaching...   \n",
       "11   RT @kaggle: Bookmark this amazing library of i...   \n",
       "12   Awesome members of our @midasIIITD team who ar...   \n",
       "13       @saanidhi @ACMMM19 Before Friday, 15th March.   \n",
       "14   We are glad to inform that Adobe is launching ...   \n",
       "15   We will email tasks to all shortlisted candida...   \n",
       "16   @ACMMM19 @ACM_MM2018 @acmmm17 @sigmm @ACM Less...   \n",
       "17   RT @kdnuggets: Face Recognition using One-Shot...   \n",
       "18   @AvinashSwamina2 @IIITDelhi No. They will be g...   \n",
       "19   We are in the process of finalizing the shortl...   \n",
       "20   @ylecun @NilayShri @the_dhumketu @debanjanbhuc...   \n",
       "21   RT @kdnuggets: Python Data Science for Beginne...   \n",
       "22   RT @stanfordnlp: Useful feature of our Python ...   \n",
       "23   @NilayShri @NilayShri, Certain thing! The next...   \n",
       "24   At @midasIIITD, we not only work hard but also...   \n",
       "25   Considering several requests to extend the dea...   \n",
       "26   RT @jeremyphoward: 39 studies about human perc...   \n",
       "27             Correction:   @midasIIITD at @IIITDelhi   \n",
       "28   Thanks much to all aspirants who have applied ...   \n",
       "29   RT @kdnuggets: Keras Hyperparameter Tuning in ...   \n",
       "..                                                 ...   \n",
       "266  RT @TensorFlow: TensorFlow 1.10.0 has been rel...   \n",
       "267  @midasIIITD is looking for motivated IIITD MTe...   \n",
       "268  @IIITDelhi @ponguru @RatnRajiv The results of ...   \n",
       "269  RT @IIITDelhi: @midasIIITD has secured rank 1 ...   \n",
       "270  RT @kdnuggets: Comparison of Top 6 Python NLP ...   \n",
       "271  Check more details of the 20th IEEE Internatio...   \n",
       "272  MR2AMC@ISM 2018 will be organized by @RatnRaji...   \n",
       "273  Our workshop proposal named, \"MR2AMC: Multimod...   \n",
       "274  @NUSComputing Congratulations Abdelhak and Pro...   \n",
       "275  RT @goodfellow_ian: One of the most anticipate...   \n",
       "276     @the_dhumketu Great to have you in @midasIIITD   \n",
       "277  Congratulation @soujanyaporia for being appoin...   \n",
       "278  @IIITDelhi @the_dhumketu Thanks team @midasIII...   \n",
       "279  RT @IIITDelhi: Congratulations @midasIIITD int...   \n",
       "280  RT @learning_pt: Profile of the 5 Indian under...   \n",
       "281  Have a look at the list of accepted papers in ...   \n",
       "282  RT @goodfellow_ian: https://t.co/hYiWI7ntyk Te...   \n",
       "283  RT @IIITDelhi: Congratulations Dr. @RatnRajiv ...   \n",
       "284  RT @ylecun: Jitendra Malik, who directs FAIR-M...   \n",
       "285  RT @kdnuggets: .@Bloomberg launches free cours...   \n",
       "286  RT @TechAtBloomberg: Missed #PyLondinium18? Wa...   \n",
       "287  RT @IIITDelhi: We are delighted to announce th...   \n",
       "288  Get ready for the annual technical fest of @II...   \n",
       "289  Congratulations Dr. @RatnRajiv and team @midas...   \n",
       "290  Congratulations MIDAS @midasIIITD intern Prakh...   \n",
       "291    MIDAS@IIITD foundation. https://t.co/LKuzyBHzjm   \n",
       "292  It feels great to be the part of @IIITDelhi. h...   \n",
       "293  Thank you, @toonzratn for designing the logo o...   \n",
       "294  We are on Facebook too. Like our page to get o...   \n",
       "295  MIDAS is a group of researchers at IIIT-Delhi ...   \n",
       "\n",
       "                     datetime  favorite_count  retweet_count media  \n",
       "0   2019-03-20 08:19:24+00:00               1              1  None  \n",
       "1   2019-03-20 02:40:07+00:00               0              4  None  \n",
       "2   2019-03-18 02:27:47+00:00               6              3  None  \n",
       "3   2019-03-17 14:22:04+00:00              15              4  None  \n",
       "4   2019-03-16 14:06:56+00:00               6              0  None  \n",
       "5   2019-03-16 09:20:29+00:00               1              1  None  \n",
       "6   2019-03-16 09:14:58+00:00               7              2  None  \n",
       "7   2019-03-16 05:13:14+00:00               7              2  None  \n",
       "8   2019-03-13 17:09:44+00:00               0              2  None  \n",
       "9   2019-03-13 04:11:24+00:00               1              0     1  \n",
       "10  2019-03-13 04:06:04+00:00               0             13  None  \n",
       "11  2019-03-12 17:43:44+00:00               0             69  None  \n",
       "12  2019-03-12 14:37:55+00:00              16              4     1  \n",
       "13  2019-03-11 14:58:30+00:00               0              0  None  \n",
       "14  2019-03-11 12:02:42+00:00               4              0  None  \n",
       "15  2019-03-11 11:54:38+00:00               3              0  None  \n",
       "16  2019-03-11 06:22:12+00:00               1              1  None  \n",
       "17  2019-03-11 06:17:20+00:00               0             64  None  \n",
       "18  2019-03-08 13:22:07+00:00               1              0  None  \n",
       "19  2019-03-08 13:15:34+00:00               8              4  None  \n",
       "20  2019-03-06 13:44:11+00:00               3              0  None  \n",
       "21  2019-03-06 11:12:30+00:00               0             22     1  \n",
       "22  2019-03-03 19:36:04+00:00               0             35  None  \n",
       "23  2019-03-03 17:09:48+00:00               1              0  None  \n",
       "24  2019-03-03 15:37:28+00:00               9              1     1  \n",
       "25  2019-03-03 14:55:31+00:00               6              2  None  \n",
       "26  2019-03-03 14:26:40+00:00               0            315  None  \n",
       "27  2019-03-02 17:43:05+00:00               1              0  None  \n",
       "28  2019-03-02 09:59:03+00:00               7              1  None  \n",
       "29  2019-02-28 14:21:21+00:00               0              4     1  \n",
       "..                        ...             ...            ...   ...  \n",
       "266 2018-08-09 05:59:57+00:00               0            265  None  \n",
       "267 2018-08-08 11:30:56+00:00               2              1  None  \n",
       "268 2018-08-08 05:53:48+00:00               3              1     1  \n",
       "269 2018-08-08 05:45:58+00:00               0              1  None  \n",
       "270 2018-08-07 07:16:33+00:00               0             40     1  \n",
       "271 2018-08-07 02:05:12+00:00               1              1  None  \n",
       "272 2018-08-07 01:58:49+00:00               1              1  None  \n",
       "273 2018-08-07 01:50:33+00:00               1              1  None  \n",
       "274 2018-08-06 17:48:23+00:00               0              0  None  \n",
       "275 2018-08-06 17:46:59+00:00               0            103     1  \n",
       "276 2018-08-06 06:06:47+00:00               0              0  None  \n",
       "277 2018-08-03 05:56:33+00:00               6              1  None  \n",
       "278 2018-08-01 11:47:15+00:00               5              1     1  \n",
       "279 2018-08-01 11:20:07+00:00               0              4  None  \n",
       "280 2018-08-01 05:06:47+00:00               0              4  None  \n",
       "281 2018-07-31 12:11:52+00:00               1              0  None  \n",
       "282 2018-07-31 02:06:26+00:00               0            264  None  \n",
       "283 2018-07-30 07:30:51+00:00               0              2  None  \n",
       "284 2018-07-28 11:07:11+00:00               0             57  None  \n",
       "285 2018-07-28 06:14:09+00:00               0            105  None  \n",
       "286 2018-07-28 06:13:48+00:00               0              7  None  \n",
       "287 2018-07-28 04:08:21+00:00               0              6  None  \n",
       "288 2018-07-27 06:46:44+00:00               3              2  None  \n",
       "289 2018-07-27 04:07:31+00:00               8              2  None  \n",
       "290 2018-07-25 05:14:35+00:00               5              1  None  \n",
       "291 2018-07-24 10:33:23+00:00               2              1  None  \n",
       "292 2018-07-24 10:12:34+00:00               2              1  None  \n",
       "293 2018-07-24 09:46:26+00:00               4              1     1  \n",
       "294 2018-07-23 16:25:05+00:00               3              1  None  \n",
       "295 2018-07-23 12:53:15+00:00               7              4  None  \n",
       "\n",
       "[296 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
